# -*- coding: utf-8 -*-
"""Stromrallye.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vgSLEzkmCKLHnABqEM_s5byH_l4_iL6l

# Bundeswettbewerb Informatik
## Aufgabe 1: Stromrallye
Links zu den Beispieleingaben:

[Beispiel 1](https://bwinf.de/fileadmin/user_upload/stromrallye0.txt)
[Beispiel 2](https://bwinf.de/fileadmin/user_upload/stromrallye1.txt)
[Beispiel 3](https://bwinf.de/fileadmin/user_upload/stromrallye2.txt)
[Beispiel 4](https://bwinf.de/fileadmin/user_upload/stromrallye3.txt)
[Beispiel 5](https://bwinf.de/fileadmin/user_upload/stromrallye4.txt)
[Beispiel 5](https://bwinf.de/fileadmin/user_upload/stromrallye5.txt)

# Erstellung der Simulationsumgebung
## Steuerung
Die Simulationsumgebung wird mithilfe der gegebenen Daten (Eingabe des Benutzers) initiiert.
Die Umgebung besteht aus einem Roboter mit gegebener Bordbatterie sowie weiteren Ersatzladungen, die auf dem Spielfeld verteilt sind und deren Ladung bekannt ist.
> Vorerst sollte der Roboter nicht am Rand des Spielfelds weiter nach außen gehen können, und dabei auf der gegenüberliegenden Seite herauskommen.
Dies wird als optionale Erweiterung später betrachtet.

Zu beachten ist hierbei, dass der Roboter seine Bordbatterie mit der Ersatzbatterie austauschen muss, sobald er sich auf deren Feld befindet.

> Beispiele hierfür sind den BwInf-Websiten zu entnehmen.

### Agent
Ein außenstehender Benutzer (lernender Agent) wird in der Lage sein, über eine Methode den Roboter in der Simulationsumgebung bewegen zu können.


#### Informationsaustausch zum Agent
Daneben wird in der Simulationsumgebung eine Belohnung (Reward) für jeden Schritt vergeben, den der Agent (lernender Benutzer) tätigt.
Diese Rewards können je nach ausgeführter Handlung des Agents auch negativ ausfallen (bestrafend).

---

Neben diesen Rewards muss der lernende Agent ebenfalls wissen, wie der aktuelle 'State' (aktueller Zustand) der Simulationsumgebung ist.
> Konkret: Wo sich der Roboter und die Ersatzladungen befinden und wie hoch die jeweiligen Ladungen sind.

## Implementierung der Simulationsumgebung als eigene Klasse in Python
### Definition der Rewards
* Schritt des Roboters 
    * Reward = +1

* Austausch der Bordbatterie mit einer Ersatzbatterie 
    * Reward = +1

* Versuch gegen die Wand zu laufen
    * Reward = -1

* Alle Batterien leer
    * Reward = +100
    * Spiel wird neu gestartet

* Bordbatterie des Roboters leer
    * Reward = -100
    * Spiel wird neu gestartet

### Definition der Steuerung
verfügbare Aktion um den Robotor in der Umgebung zu steuern:
> eindeutige Definition als Zahlenwert von 0 bis 3

* nach oben: 0
* nach unten: 1
* nach links: 2
* nach rechts: 3
"""

import numpy as np
import time
import sys
if sys.version_info.major == 2:
    import Tkinter as tk
else:
    import tkinter as tk


UNIT = 40


class Environment(tk.Tk, object):
    def __init__(self, size: int, roboter: tuple, anzahl_batterien: int, batterien: list):
        """ erstellt eine Umgebung mit der gegebenen Eingabe """
        super(Environment, self).__init__()

        # TODO IWAS origin ?!
        self.origin = np.array([UNIT/2, UNIT/2])

        self.size = size

        # Batterien:
        self.anzahl_batterien = anzahl_batterien
        # die Batterien werden gesammelt in einem Dictionary ebenfalls wie der Roboter in der Form:
        # (x, y, ladung) gespeichert
        # wobei (x, y, ladung) als Key des Dictionary fungiert und die id des Text-Widgets von Tkinter der jeweilige Value ist
        # der Value wird später erstellt
        self.batterien = dict.fromkeys(batterien)

        # Die Positon des Roboters oder der Batterien werden in einem Dictionary mit der Form (x, y, ladung) gespeichert
        # Key ist (x, y, ladung) und der Value ist eine Liste mit der ID des grünen Quadrats (stellt den Roboter da) und mit der ID des Text-Widgets
        self.roboter = dict.fromkeys([roboter])

        self.action_space = [0, 1, 2, 3]
        self.n_actions = len(self.action_space)
        self.title('Stromrallye')
        self.geometry('{0}x{1}'.format(self.size * UNIT, self.size * UNIT))
        self._build_stromrallye()

    def _build_stromrallye(self):
        """ in dieser Methode wird das Spielbrett auf Ausgangsstellung auf einer Zeichenfläche (Canvas) gezeichnet """

        # Canvas objekt wird erstellt
        # weißer Hintergrund mit gegebener, quadratischer Größe des Spielbretts
        self.canvas = tk.Canvas(
            self, bg='white',
            height=self.size * UNIT,
            width=self.size * UNIT)

        # Gitter erstellen
        for spalte in range(0, self.size * UNIT, UNIT):
            x0, y0, x1, y1 = spalte, 0, spalte, self.size * UNIT
            self.canvas.create_line(x0, y0, x1, y1)
        for reihe in range(0, self.size * UNIT, UNIT):
            x0, y0, x1, y1 = 0, reihe, self.size * UNIT, reihe
            self.canvas.create_line(x0, y0, x1, y1)

        # Ersatzbatterien mit aktuellem Akkustand zeichnen
        for key in self.batterien.keys():
            x, y, ladung = key

            # Mittelpunkt des Feldes der jeweiligen Ersatzbatterie
            batt_center = np.array([(x-1) * UNIT, (y-1) * UNIT]) + self.origin

            # gelbes Quadrat als Zeichen für eine Ersatzbatterie
            self.canvas.create_rectangle(
                batt_center[0] - 15, batt_center[1] - 15,
                batt_center[0] + 15, batt_center[1] + 15,
                fill='yellow'
            )

            # ein Text mit der Ladung der Batterie wird im Mittelpunkt des Feldes angezeigt
            # Value des Dictionary self.batterien wird mit der ID des Text-Widgets von Tkinter versehen
            self.batterien[key] = self.canvas.create_text(
                *batt_center, text=ladung)

        # Roboter zeichnen:
        x, y, ladung = list(self.roboter.keys())[0]
        robo_center = np.array([(x-1) * UNIT, (y-1) * UNIT]) + self.origin

        self.roboter[(x, y, ladung)] = []
        # grünes Quadrat als Zeichen für den Roboter
        # das grüne Quadrat wird mit dem Tag 'roboter' versehen, um später darauf zugreifen zu können
        self.roboter[(x, y, ladung)].append(self.canvas.create_rectangle(
            robo_center[0] - 15, robo_center[1] - 15,
            robo_center[0] + 15, robo_center[1] + 15,
            fill='green', tags=('roboter')
        ))

        # Text mit aktueller Ladung der Bordbatterie
        # das Text-Widget wird mit 'roboter_batterie' versehen
        self.roboter[(x, y, ladung)].append(self.canvas.create_text(
            *robo_center, text=f'{ladung}', tags=('roboter_batterie')
        ))

        #  self.canvas.itemconfigure('ersatzbatterie_2', text='22')

        # # IWAS ANDERES hell?!
        # hell1_center = origin + np.array([UNIT * 2, UNIT])
        # self.hell = self.canvas.create_rectangle(
        #     hell1_center[0] - 15, hell1_center[1] - 15,
        #     hell1_center[0] + 15, hell1_center[1] + 15,
        #     fill='black')
        # # hell
        # hell2_center = origin + np.array([UNIT, UNIT*2])
        # self.hell2  = self.canvas.create_rectangle(
        #     hell1_center[0] - 15, hell1_center[1] - 15,
        #     hell1_center[0] + 15, hell1_center[1] + 15,
        #     fill='black')

        # # create oval
        # oval_center = origin + UNIT * 2
        # self.oval = self.canvas.create_oval(
        #     oval_center[0] - 15, oval_center[1] - 15,
        #     oval_center[0] + 15, oval_center[1] + 15,
        #     fill='yellow')

        # # create red rect
        # self.rect = self.canvas.create_rectangle(
        #     origin[0] - 15, origin[1] - 15,
        #     origin[0] + 15, origin[1] + 15,
        #     fill='red')

        # Canvas pack
        self.canvas.pack()

    def _update_gui(self):
        """ aktualisiert die angezeigten Zahlen und die Position des Roboters auf dem GUI """

        # Roboter aktualisieren:
        # grünes Quadrat bewegen und die Zahl für die Ladung der Bordbatterie aktualisieren
        (x, y, ladung), [id_quadrat, id_text] = list(self.roboter.items())[0]
        # x- und y-Koordinate der alten Position
        old_coords = np.array(self.canvas.coords(id_quadrat)[0:2])
        new_coords = np.array([(x-1) * UNIT+5, (y-1) * UNIT+5])
        diff = new_coords - old_coords

        # Quadrat und Text um die Veränderung bewegen
        self.canvas.move(id_quadrat, *diff)
        self.canvas.move(id_text, *diff)

        # Anzeige der Ladung aktualisieren
        self.canvas.itemconfigure(id_text, text=ladung)

        # Akkuladungen der Ersatzbatterien wird aktualisiert
        for item in self.batterien.items():
            (x, y, ladung), id = item
            self.canvas.itemconfigure(id, text=ladung)

        # die Position des Roboters wird aktualisiert
        # self.canvas.move()

        self.canvas.pack()

    def reset(self):
        self.update()
        time.sleep(0.5)
        self.canvas.delete(self.rect)
        origin = np.array([20, 20])

    def step(self, action: int):
        """ bewegt den Roboter in der Umgebung
            nach oben: 0
            nach unten: 1
            nach links: 2
            nach rechts: 3
        """
        # speichert den auszuführenden Vorgang
        #base_action = np.array([0, 0])
        (x, y, ladung_roboter), id_liste = list(self.roboter.items())[0]
        self.roboter.pop((x, y, ladung_roboter))

        # TODO:
        # Roboter an Wand und kann sich nicht mehr weiter bewegen +
        # negativer Reward bei Laufen gegen die Wand
        if action == 0:
            if y > 1:
                # hoch: y-Koordinate -1
                y -= 1
            else:
                # neg. Reward
                pass

        elif action == 1:
            if y < self.size:
                # runter: y-Koordinate +1
                y += 1
            else:
                # neg. Reward
                print("Noo")

        elif action == 2:
            if x > 1:
                # links: x-Koordinate -1
                x -= 1
            else:
                # neg. Reward
                pass

        elif action == 3:
            if x < self.size:
                # rechts: x-Koordinate +1
                x += 1
            else:
                # neg. Reward
                pass
        
        # Aktualisierung der Klassenvariable
        self.roboter[(x, y, ladung_roboter)] = id_liste
        self._update_gui()


        # Überprüfung, ob sich der Roboter jetzt auf einem Feld mit einer Ersatzbatterie befindet
        for koordinaten, ladung_batterie in zip([koordinaten[0:2] for koordinaten in self.batterien.keys()], [ladung[2] for ladung in self.batterien.keys()]):
            if (x, y) == koordinaten:
                self.batterien[(x, y, ladung_roboter)] = self.batterien.pop((x, y, ladung_batterie))
                self.roboter[(x, y, ladung_batterie)] = self.roboter.pop((x, y, ladung_roboter))
            
        

        self._update_gui()


if __name__ == "__main__":

    # eingabe = """
    # 5
    # 3,5,9
    # 3
    # 5,1,3
    # 1,2,2
    # 5,4,3
    # """

    # TODO: Konvertierung der Eingabe im Tkinter EingabeFenster dann:

    # def _convert_eingabe(self, eingabe: list):
    #     """ Konvertierung der gegebenen Eingabe im gegebenen Format, siehe oben (oder auf der BwInf-Website) """
    # new_eingabe = []
    # for element in eingabe:
    #     if not ',' in element:
    #         new_eingabe.append(int(element))
    #     else:
    #         element = list(element)
    #         x, y, ladung = int(element[0]), int(element[2]), int(element[4])
    #         new_element = [x, y, ladung]
    #         new_eingabe.append(new_element)
    # return new_eingabe

    # self.size = int(eingabe.pop(0))
    # eingabe = self._convert_eingabe(eingabe)
    # self.roboter = list(eingabe.pop(0))

    # self.anzahl_batterien = eingabe.pop(0)

    # # die restlichen Batterien werden hinzugefügt und in Reihenfolge in einem Dictionary gespeichert
    # self.batterien = dict()
    # for n in range(self.anzahl_batterien):
    #     self.batterien[n] = eingabe.pop(0)

    # erste Zeile: Größe des Spielbretts (quadratisch)
    # zweite Zeile: Koordinaten des Robotors und die Ladung seiner Batterie
    # dritte Zeile: Anzahl der restlichen Batterien, die auf dem Spielfeld verteilt sind
    # ab der vierten Zeile: Koordinaten einer Batterie, zusammen mit ihrer Ladung
    # Schreibweise: x-Koordinate, y-Koordinate, Ladung

    eingabe = """
    5
    3,5,9
    3
    5,1,3
    1,2,2
    5,4,3
    """
    size = 5
    roboter = (3, 5, 9)
    anzahl_batterien = 3
    batterien = [
        (5, 1, 3),
        (1, 2, 2),
        (5, 4, 3)
    ]

    env = Environment(
        size=size, roboter=roboter,
        anzahl_batterien=anzahl_batterien,
        batterien=batterien
    )

    env.step(1)

    env.mainloop()

# eingabe = """
# 5
# 3,5,9
# 3
# 5,1,3
# 1,2,2
# 5,4,3
# """
# env = Environment(eingabe)

# env.move(0)
# env.move(2)
# env.roboter

# import numpy as np
# import gym

# from keras.models import Sequential
# from keras.layers import Dense, Activation, Flatten
# from keras.optimizers import Adam

# from rl.agents.dqn import DQNAgent
# from rl.policy import EpsGreedyQPolicy
# from rl.memory import SequentialMemory

# ENV_NAME = 'CartPole-v0'

# # Get the environment and extract the number of actions available in the Cartpole problem
# env = gym.make(ENV_NAME)
# np.random.seed(123)
# env.seed(123)
# nb_actions = env.action_space.n
# print(env.action_space)

# model = Sequential()
# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))
# model.add(Dense(16))
# model.add(Activation('relu'))
# model.add(Dense(nb_actions))
# model.add(Activation('linear'))
# print(model.summary())

# policy = EpsGreedyQPolicy()
# memory = SequentialMemory(limit=50000, window_length=1)
# dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,
#     target_model_update=1e-2,
#     policy=policy
#     )
# dqn.compile(Adam(lr=1e-3), metrics=['mae'])

# # Okay, now it's time to learn something! We visualize the training here for show, but this slows down training quite a lot.
# dqn.fit(env, nb_steps=5000, visualize=True, verbose=2)
