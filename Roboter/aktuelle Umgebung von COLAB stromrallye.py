# -*- coding: utf-8 -*-
"""Stromrallye.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vgSLEzkmCKLHnABqEM_s5byH_l4_iL6l

# Bundeswettbewerb Informatik
## Aufgabe 1: Stromrallye
Links zu den Beispieleingaben:

[Beispiel 1](https://bwinf.de/fileadmin/user_upload/stromrallye0.txt)
[Beispiel 2](https://bwinf.de/fileadmin/user_upload/stromrallye1.txt)
[Beispiel 3](https://bwinf.de/fileadmin/user_upload/stromrallye2.txt)
[Beispiel 4](https://bwinf.de/fileadmin/user_upload/stromrallye3.txt)
[Beispiel 5](https://bwinf.de/fileadmin/user_upload/stromrallye4.txt)
[Beispiel 5](https://bwinf.de/fileadmin/user_upload/stromrallye5.txt)

# Erstellung der Simulationsumgebung
## Steuerung
Die Simulationsumgebung wird mithilfe der gegebenen Daten (Eingabe des Benutzers) initiiert.
Die Umgebung besteht aus einem Roboter mit gegebener Bordbatterie sowie weiteren Ersatzladungen, die auf dem Spielfeld verteilt sind und deren Ladung bekannt ist.
> Vorerst sollte der Roboter nicht am Rand des Spielfelds weiter nach außen gehen können, und dabei auf der gegenüberliegenden Seite herauskommen.
Dies wird als optionale Erweiterung später betrachtet.

Zu beachten ist hierbei, dass der Roboter seine Bordbatterie mit der Ersatzbatterie austauschen muss, sobald er sich auf deren Feld befindet.

> Beispiele hierfür sind den BwInf-Websiten zu entnehmen.

### Agent
Ein außenstehender Benutzer (lernender Agent) wird in der Lage sein, über eine Methode den Roboter in der Simulationsumgebung bewegen zu können.


#### Informationsaustausch zum Agent
Daneben wird in der Simulationsumgebung eine Belohnung (Reward) für jeden Schritt vergeben, den der Agent (lernender Benutzer) tätigt.
Diese Rewards können je nach ausgeführter Handlung des Agents auch negativ ausfallen (bestrafend).

---

Neben diesen Rewards muss der lernende Agent ebenfalls wissen, wie der aktuelle 'State' (aktueller Zustand) der Simulationsumgebung ist.
> Konkret: Wo sich der Roboter und die Ersatzladungen befinden und wie hoch die jeweiligen Ladungen sind.

## Implementierung der Simulationsumgebung als eigene Klasse in Python
### Definition der Rewards
* Schritt des Roboters 
    * Reward = +1

* Austausch der Bordbatterie mit einer Ersatzbatterie 
    * Reward = +1

* Versuch gegen die Wand zu laufen
    * Reward = -1

* Alle Batterien leer
    * Reward = +100
    * Spiel wird neu gestartet

* Bordbatterie des Roboters leer
    * Reward = -100
    * Spiel wird neu gestartet

### Definition der Steuerung
verfügbare Aktion um den Robotor in der Umgebung zu steuern:
> eindeutige Definition als Zahlenwert von 0 bis 3

* nach oben: 0
* nach unten: 1
* nach links: 2
* nach rechts: 3
"""

import numpy as np
import time
import sys
if sys.version_info.major == 2:
    import Tkinter as tk
else:
    import tkinter as tk


UNIT = 40

class Environment(tk.Tk, object):
    def __init__(self, eingabe: str):
        """ erstellt eine Umgebung mit der gegebenen Eingabe """
        super(Environment, self).__init__()

        # TODO IWAS origin ?!
        self.origin = np.array([UNIT/2, UNIT/2])

        eingabe = eingabe.split()
        self.size = int(eingabe.pop(0))
        # Kovertiert die Eingabe
        eingabe = self._convert_eingabe(eingabe)
        
        
        # Die Positon des Roboters oder der Batterien werden in einer Liste der Form (x, y, ladung) gespeichert
        self.roboter = list(eingabe.pop(0))
        self.anzahl_batterien = eingabe.pop(0)

        # die restlichen Batterien werden hinzugefügt und in Reihenfolge in einem Dictionary gespeichert
        self.batterien = dict()
        for n in range(self.anzahl_batterien):
            self.batterien[n] = eingabe.pop(0)


        self.action_space = [0, 1, 2, 3]
        self.n_actions = len(self.action_space)
        self.title('Stromrallye')
        self.geometry('{0}x{1}'.format(self.size * UNIT, self.size * UNIT))
        self._build_stromrallye()
        self._update_gui()

        # self.batterien[0][2] = 5
        # self._update_gui()

        
    def _convert_eingabe(self, eingabe: list):
        """ Konvertierung der gegebenen Eingabe im gegebenen Format, siehe oben (oder auf der BwInf-Website) """
        new_eingabe = []
        for element in eingabe:
            if not ',' in element:
                new_eingabe.append(int(element))
            else:
                element = list(element)
                x, y, ladung = int(element[0]), int(element[2]), int(element[4])
                new_element = [x, y, ladung]
                new_eingabe.append(new_element)               
        return new_eingabe
    
    def _build_stromrallye(self):
        """ in dieser Methode wird das Spielbrett auf Ausgangsstellung auf einer Zeichenfläche (Canvas) gezeichnet """

        # Canvas objekt wird erstellt
        # weißer Hintergrund mit gegebener, quadratischer Größe des Spielbretts
        self.canvas = tk.Canvas(
            self, bg='white', 
            height=self.size * UNIT,
            width=self.size * UNIT)

        # Gitter erstellen
        for spalte in range(0, self.size * UNIT, UNIT):
            x0, y0, x1, y1 = spalte, 0, spalte, self.size * UNIT
            self.canvas.create_line(x0, y0, x1, y1)
        for reihe in range(0, self.size * UNIT, UNIT):
            x0, y0, x1, y1 = 0, reihe, self.size * UNIT, reihe
            self.canvas.create_line(x0, y0, x1, y1)


        # Ersatzbatterien mit aktuellem Akkustand zeichnen
        for item in self.batterien.items():
            index, batterie_eigenschaften = item
            x, y, ladung = batterie_eigenschaften

            # Mittelpunkt des Feldes der jeweiligen Ersatzbatterie
            batt_center = np.array([(x-1)* UNIT, (y-1) * UNIT]) + self.origin

            # gelbes Quadrat als Zeichen für eine Ersatzbatterie
            self.canvas.create_rectangle(
                batt_center[0] - 15, batt_center[1] - 15,
                batt_center[0] + 15, batt_center[1] + 15,
                fill='yellow'
            )

            # ein Text mit der Ladung der Batterie wird im Mittelpunkt des Feldes angezeigt
            # die Text-Widgets der Canvas-Zeichenfläche werden mit zusätzlichen Tags versehen, damit diese später auf dem GUI verändert werden können:
            # 1. ein Tag mit 'ersatzbatterie' um auf alle Ersatzbatterien zugreifen zu können
            # 2. ein Tag mit 'ersatzbatterie_{index}' --> z.B. ersatzbatterie_1 gibt die zweite Ersatzbatterie an
            # die Text-Widgets können dann später über canvas.itemconfigure verändert werden
            self.canvas.create_text(
                *batt_center, text=f'{ladung}', tags=('ersatzbatterie', f'ersatzbatterie_{index}')
            )
        
        # Roboter zeichnen:
        x, y, ladung = self.roboter
        robo_center = np.array([(x-1) * UNIT, (y-1) * UNIT]) + self.origin

        # grünes Quadrat als Zeichen für den Roboter
        # das grüne Quadrat wird mit dem Tag 'roboter' versehen, um später darauf zugreifen zu können
        self.canvas.create_rectangle(
            robo_center[0] - 15, robo_center[1] - 15,
            robo_center[0] + 15, robo_center[1] + 15,
            fill='green', tags=('roboter')
        )

        # Text mit aktueller Ladung der Bordbatterie
        # das Text-Widget wird mit 'roboter_batterie' versehen
        self.canvas.create_text(
            *robo_center, text=f'{ladung}', tags=('roboter_batterie')
        )

        



        


        #  self.canvas.itemconfigure('ersatzbatterie_2', text='22')
        



        # # IWAS ANDERES hell?!
        # hell1_center = origin + np.array([UNIT * 2, UNIT])
        # self.hell = self.canvas.create_rectangle(
        #     hell1_center[0] - 15, hell1_center[1] - 15,
        #     hell1_center[0] + 15, hell1_center[1] + 15,
        #     fill='black')
        # # hell
        # hell2_center = origin + np.array([UNIT, UNIT*2])
        # self.hell2  = self.canvas.create_rectangle(
        #     hell1_center[0] - 15, hell1_center[1] - 15,
        #     hell1_center[0] + 15, hell1_center[1] + 15,
        #     fill='black')

        # # create oval
        # oval_center = origin + UNIT * 2
        # self.oval = self.canvas.create_oval(
        #     oval_center[0] - 15, oval_center[1] - 15,
        #     oval_center[0] + 15, oval_center[1] + 15,
        #     fill='yellow')
        
        # # create red rect
        # self.rect = self.canvas.create_rectangle(
        #     origin[0] - 15, origin[1] - 15,
        #     origin[0] + 15, origin[1] + 15,
        #     fill='red')
            
        
        # Canvas pack
        self.canvas.pack()

    def _update_gui(self):
        """ aktualisiert die angezeigten Zahlen und die Position des Roboters auf dem GUI """

        #

        # Roboter aktualisieren:
        # grünes Quadrat bewegen und die Zahl für die Ladung der Bordbatterie aktualisieren
        x, y, ladung = (1, 2, 1)
        new_robo = np.array([(x-1) * UNIT, (y-1) * UNIT]) #+ self.origin
        self.canvas.itemconfigure('roboter', x=new_robo[0], y=new_robo[1])
        self.canvas.itemconfigure('roboter_batterie', text=f'{ladung}')



        # # Akkuladung der Ersatzbatterien wird aktualisiert
        # # TODO self.batterie ist ein Dictionary! 
        # for batterie in self.batterien:
        #     x, y, ladung = batterie
        #     batt_center = np.array([(x-1)* UNIT, (y-1) * UNIT]) + self.origin
        #     self.canvas.create_text(
        #         *batt_center, text=f'{ladung}'
        #     )

        # die Position des Roboters wird aktualisiert
        #self.canvas.move()

        self.canvas.pack()

    
    def reset(self):
        self.update()
        time.sleep(0.5)
        self.canvas.delete(self.rect)
        origin = np.array([20, 20])


    def move(self, action: int):
        """ bewegt den Roboter in der Umgebung
            nach oben: 0
            nach unten: 1
            nach links: 2
            nach rechts: 3
        """

        # TODO:
        # Roboter an Wand und kann sich nicht mehr weiter bewegen +
        # negativer Reward bei Laufen gegen die Wand
        if action == 0:
            # y-Koordinate -1
            self.roboter[1] -= 1
        elif action == 1:
            # y-Koordinate +1
            self.roboter[1] += 1 
        elif action == 2:
            # x-Koordinate -1
            self.roboter[0] -= 1
        elif action == 3:
            # x-Koordinate +1
            self.roboter[0] += 1

if __name__ == "__main__":
    
    # eingabe = """
    # 5
    # 3,5,9
    # 3
    # 5,1,3
    # 1,2,2
    # 5,4,3
    # """

    # erste Zeile: Größe des Spielbretts (quadratisch)
    # zweite Zeile: Koordinaten des Robotors und die Ladung seiner Batterie
    # dritte Zeile: Anzahl der restlichen Batterien, die auf dem Spielfeld verteilt sind
    # ab der vierten Zeile: Koordinaten einer Batterie, zusammen mit ihrer Ladung
    # Schreibweise: x-Koordinate, y-Koordinate, Ladung

    eingabe = """
    5
    3,5,9
    3
    5,1,3
    1,2,2
    5,4,3
    """
    env = Environment(eingabe)
    env.mainloop()

# eingabe = """
# 5
# 3,5,9
# 3
# 5,1,3
# 1,2,2
# 5,4,3
# """
# env = Environment(eingabe)

# env.move(0)
# env.move(2)
# env.roboter

# import numpy as np
# import gym

# from keras.models import Sequential
# from keras.layers import Dense, Activation, Flatten
# from keras.optimizers import Adam

# from rl.agents.dqn import DQNAgent
# from rl.policy import EpsGreedyQPolicy
# from rl.memory import SequentialMemory

# ENV_NAME = 'CartPole-v0'

# # Get the environment and extract the number of actions available in the Cartpole problem
# env = gym.make(ENV_NAME)
# np.random.seed(123)
# env.seed(123)
# nb_actions = env.action_space.n
# print(env.action_space)

# model = Sequential()
# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))
# model.add(Dense(16))
# model.add(Activation('relu'))
# model.add(Dense(nb_actions))
# model.add(Activation('linear'))
# print(model.summary())

# policy = EpsGreedyQPolicy()
# memory = SequentialMemory(limit=50000, window_length=1)
# dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,
#     target_model_update=1e-2,
#     policy=policy
#     )
# dqn.compile(Adam(lr=1e-3), metrics=['mae'])

# # Okay, now it's time to learn something! We visualize the training here for show, but this slows down training quite a lot. 
# dqn.fit(env, nb_steps=5000, visualize=True, verbose=2)